#!/usr/bin/env python

# å¸¸ç”¨æŒ‡ä»¤ï¼š
"""
python autograde.py --clean all          # æ¸…ç†base_pathå’Œå½“å‰ç›®å½•çš„æ‰€æœ‰æ–‡ä»¶
python autograde.py --parallel 20 --resume --export all  # å¹¶å‘20ä¸ªè¿›ç¨‹è¯„åˆ†ï¼Œå¯¼å‡ºæ‰€æœ‰æ ¼å¼ï¼Œä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­
"""


import os
import sys
import json
import glob
import argparse
import logging
import concurrent.futures
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from tqdm import tqdm
from openai import OpenAI

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from grader import Grader, GradingCriteria
from similarity_checker import SimilarityChecker
from progress_manager import ProgressManager, CacheManager
from score_analyzer import StatisticsAnalyzer
from export_utils import ExportManager


# ç»ˆç«¯é¢œè‰²ç¾åŒ–
class Colors:
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    MAGENTA = '\033[95m'
    BOLD = '\033[1m'
    END = '\033[0m'


def setup_logging(log_level: str = 'INFO') -> logging.Logger:
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    logger = logging.getLogger(__name__)
    logger.setLevel(getattr(logging, log_level.upper()))

    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(
        f"grading_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
        mode='w',
        encoding='utf-8'
    )
    file_handler.setLevel(logging.INFO)
    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(file_formatter)
    logger.addHandler(file_handler)

    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.WARNING)
    console_formatter = logging.Formatter(f'{Colors.YELLOW}%(levelname)s{Colors.END}: %(message)s')
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)

    return logger


def load_config(config_path: str = 'config.json') -> Dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    path = Path(config_path)
    if not path.exists():
        print(f"{Colors.YELLOW}é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}{Colors.END}")
        default_config = {
            "base_path": "./homework",
            "api_key": "YOUR_API_KEY",
            "base_url": "YOUR_API_BASE_URL",
            "model": "gpt-4",
            "request_timeout": 60,
            "max_retries": 3,
            "retry_delay": 5,
            "max_workers": 5,
            "similarity_threshold": 0.85
        }
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(default_config, f, indent=4)
        print(f"å·²åˆ›å»ºé…ç½®æ–‡ä»¶æ¨¡æ¿: {config_path}")
        sys.exit(1)

    with open(path, 'r', encoding='utf-8') as f:
        config = json.load(f)

    # è®¾ç½®é»˜è®¤å€¼
    config.setdefault('request_timeout', 60)
    config.setdefault('max_retries', 3)
    config.setdefault('retry_delay', 5)
    config.setdefault('max_workers', 5)
    config.setdefault('similarity_threshold', 0.85)

    return config


def get_submissions(base_path: str) -> List[Tuple[str, Path]]:
    """è·å–æ‰€æœ‰å­¦ç”Ÿæäº¤çš„æ–‡ä»¶"""
    submissions_dir = Path(base_path) / 'submissions'
    if not submissions_dir.is_dir():
        raise FileNotFoundError(f"æœªæ‰¾åˆ° submissions æ–‡ä»¶å¤¹: {submissions_dir}")

    submissions = []
    py_files = list(submissions_dir.glob('*.py'))

    for file_path in py_files:
        if '_' in file_path.name:
            student_id = file_path.name.split('_')[0]
        else:
            student_id = file_path.stem

        if file_path.stat().st_size == 0:
            logging.warning(f"æ–‡ä»¶ä¸ºç©ºï¼Œå·²è·³è¿‡: {file_path.name}")
            continue

        submissions.append((student_id, file_path))

    return submissions


def get_template_content(base_path: str) -> str:
    """è¯»å–å‚è€ƒç­”æ¡ˆæ¨¡æ¿"""
    template_path = Path(base_path) / 'template.py'
    if not template_path.is_file():
        raise FileNotFoundError(f"æœªæ‰¾åˆ° template.py æ–‡ä»¶: {template_path}")

    with open(template_path, 'r', encoding='utf-8') as f:
        return f.read()


def clean_previous_results(config_file: str = 'config.json') -> bool:
    """æ¸…ç†ä¹‹å‰çš„è¯„åˆ†ç»“æœæ–‡ä»¶"""
    try:
        # è¯»å–é…ç½®è·å–base_path
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
            base_path = config.get('base_path', '.')

        # å®šä¹‰è¦æ¸…ç†çš„æ–‡ä»¶æ¨¡å¼
        patterns = [
            'grading_results_*.csv',
            'grading_report_*.xlsx',
            'grading_report_*.md',
            'grading_data_*.json',
            'statistics_report.txt',
            'score_distribution.png',
            'grading_progress.json'
        ]

        cleaned_files = []

        # æ¸…ç†base_pathä¸‹çš„æ–‡ä»¶ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        for pattern in patterns:
            file_pattern = os.path.join(base_path, pattern)
            matching_files = glob.glob(file_pattern)

            for file_path in matching_files:
                try:
                    os.remove(file_path)
                    cleaned_files.append(os.path.basename(file_path))
                except PermissionError:
                    file_name = os.path.basename(file_path)
                    print(f"âš ï¸  è·³è¿‡æ­£åœ¨ä½¿ç”¨çš„æ–‡ä»¶: {file_name}")
                except OSError as e:
                    print(f"âš ï¸  æ— æ³•åˆ é™¤æ–‡ä»¶ {file_path}: {e}")

        # æ¸…ç†reportsç›®å½•ä¸‹çš„æ–‡ä»¶
        reports_path = os.path.join(base_path, 'reports')
        if os.path.exists(reports_path):
            for pattern in patterns:
                file_pattern = os.path.join(reports_path, pattern)
                matching_files = glob.glob(file_pattern)

                for file_path in matching_files:
                    try:
                        os.remove(file_path)
                        cleaned_files.append(f"reports/{os.path.basename(file_path)}")
                    except PermissionError:
                        file_name = os.path.basename(file_path)
                        print(f"âš ï¸  è·³è¿‡æ­£åœ¨ä½¿ç”¨çš„æ–‡ä»¶: reports/{file_name}")
                    except OSError as e:
                        print(f"âš ï¸  æ— æ³•åˆ é™¤æ–‡ä»¶ {file_path}: {e}")

        if cleaned_files:
            print(f"ğŸ—‘ï¸  å·²æ¸…ç† {len(cleaned_files)} ä¸ªæ–‡ä»¶:")
            for file_name in cleaned_files:
                print(f"   - {file_name}")
        else:
            print("âœ… æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¸…ç†çš„æ–‡ä»¶")

        return True

    except Exception as e:
        print(f"âŒ æ¸…ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False


def clean_local_directory() -> bool:
    """æ¸…ç†å½“å‰è¿è¡Œç›®å½•ä¸­çš„æ®‹ç•™æ–‡ä»¶"""
    try:
        # å®šä¹‰è¦æ¸…ç†çš„æ–‡ä»¶æ¨¡å¼ï¼ˆåœ¨å½“å‰ç›®å½•ï¼‰
        patterns = [
            'grading_results_*.csv',
            'grading_report_*.xlsx',
            'grading_report_*.md',
            'grading_data_*.json',
            'statistics_report.txt',
            'score_distribution.png',
            'grading_progress.json',
            'grading*.log',
            '*.log'  # æ¸…ç†æ‰€æœ‰æ—¥å¿—æ–‡ä»¶
        ]

        cleaned_files = []

        # æ¸…ç†å½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶
        for pattern in patterns:
            matching_files = glob.glob(pattern)

            for file_path in matching_files:
                # è·³è¿‡é‡è¦çš„é…ç½®æ–‡ä»¶
                if os.path.basename(file_path) in ['config.json', 'grading_criteria_example.json']:
                    continue

                try:
                    os.remove(file_path)
                    cleaned_files.append(os.path.basename(file_path))
                except PermissionError:
                    file_name = os.path.basename(file_path)
                    print(f"âš ï¸  è·³è¿‡æ­£åœ¨ä½¿ç”¨çš„æ–‡ä»¶: {file_name}")
                except OSError as e:
                    print(f"âš ï¸  æ— æ³•åˆ é™¤æ–‡ä»¶ {file_path}: {e}")

        # æ¸…ç†å½“å‰ç›®å½•ä¸‹reportsç›®å½•
        reports_path = './reports'
        if os.path.exists(reports_path):
            for pattern in patterns[:-2]:  # ä¸åŒ…æ‹¬æ—¥å¿—æ–‡ä»¶
                file_pattern = os.path.join(reports_path, pattern)
                matching_files = glob.glob(file_pattern)

                for file_path in matching_files:
                    try:
                        os.remove(file_path)
                        cleaned_files.append(f"reports/{os.path.basename(file_path)}")
                    except PermissionError:
                        file_name = os.path.basename(file_path)
                        print(f"âš ï¸  è·³è¿‡æ­£åœ¨ä½¿ç”¨çš„æ–‡ä»¶: reports/{file_name}")
                    except OSError as e:
                        print(f"âš ï¸  æ— æ³•åˆ é™¤æ–‡ä»¶ {file_path}: {e}")

        if cleaned_files:
            print(f"ğŸ—‘ï¸  å·²ä»å½“å‰ç›®å½•æ¸…ç† {len(cleaned_files)} ä¸ªæ–‡ä»¶:")
            for file_name in cleaned_files:
                print(f"   - {file_name}")
        else:
            print("âœ… å½“å‰ç›®å½•æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¸…ç†çš„æ–‡ä»¶")

        return True

    except Exception as e:
        print(f"âŒ æ¸…ç†æœ¬åœ°æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False


def grade_single_submission(args: Tuple) -> Dict:
    """è¯„åˆ†å•ä¸ªä½œä¸šï¼ˆç”¨äºå¹¶å‘ï¼‰"""
    student_id, file_path, grader, template_content, progress_manager = args

    try:
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡
        if progress_manager and progress_manager.should_skip(student_id):
            return None

        # æ ‡è®°ä¸ºæ­£åœ¨å¤„ç†
        if progress_manager:
            progress_manager.mark_in_progress(student_id)

        # è¯»å–å­¦ç”Ÿä»£ç 
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            submission_content = f.read()

        # è¯„åˆ†
        result = grader.grade(
            student_id=student_id,
            submission_content=submission_content,
            template_content=template_content
        )

        # æ›´æ–°è¿›åº¦
        if progress_manager:
            if result['success']:
                progress_manager.mark_completed(student_id, result)
            else:
                progress_manager.mark_failed(student_id, result.get('comment', 'Unknown error'))

        return result

    except Exception as e:
        logging.error(f"è¯„åˆ†å¤±è´¥ {student_id}: {e}")
        if progress_manager:
            progress_manager.mark_failed(student_id, str(e))
        return {
            'student_id': student_id,
            'score': 0,
            'comment': f'è¯„åˆ†å¤±è´¥: {str(e)}',
            'success': False
        }


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    # å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(
        description='è‡ªåŠ¨Pythonä½œä¸šè¯„åˆ†ç³»ç»Ÿ v2.0',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹ï¼š
  %(prog)s                              # æ­£å¸¸è¯„åˆ†
  %(prog)s --clean base                 # ä»…æ¸…ç†base_pathç›®å½•
  %(prog)s --clean local                # ä»…æ¸…ç†å½“å‰ç›®å½•
  %(prog)s --clean all                  # æ¸…ç†ä¸¤ä¸ªç›®å½•
  %(prog)s --resume                     # ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­
  %(prog)s --parallel 4                 # ä½¿ç”¨4ä¸ªå¹¶å‘è¿›ç¨‹
  %(prog)s --export all                 # å¯¼å‡ºæ‰€æœ‰æ ¼å¼
  %(prog)s --student 12345678           # åªè¯„åˆ†ç‰¹å®šå­¦ç”Ÿ

æ¸…ç†åŠŸèƒ½ï¼š
  æ¸…ç†æ“ä½œæ˜¯ç‹¬ç«‹çš„ï¼Œåªæ¸…ç†æ–‡ä»¶ä¸æ‰§è¡Œè¯„åˆ†ã€‚
  --clean é€‰é¡¹ä¸å…¶ä»–è¯„åˆ†é€‰é¡¹äº’æ–¥ã€‚
        """
    )
    parser.add_argument('--config', '-c', default='config.json', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume', '-r', action='store_true', help='ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­')
    parser.add_argument('--retry-failed', action='store_true', help='é‡è¯•å¤±è´¥çš„ä½œä¸š')
    parser.add_argument('--no-cache', action='store_true', help='ä¸ä½¿ç”¨ç¼“å­˜')
    parser.add_argument('--no-similarity', action='store_true', help='è·³è¿‡ç›¸ä¼¼åº¦æ£€æµ‹')
    parser.add_argument('--parallel', '-p', type=int, default=1, help='å¹¶å‘æ•°ï¼ˆé»˜è®¤1ï¼‰')
    parser.add_argument('--export', '-e', choices=['csv', 'excel', 'json', 'markdown', 'all'],
                       default='excel', help='å¯¼å‡ºæ ¼å¼')
    parser.add_argument('--criteria', help='è‡ªå®šä¹‰è¯„åˆ†æ ‡å‡†æ–‡ä»¶')
    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                       default='INFO', help='æ—¥å¿—çº§åˆ«')
    parser.add_argument('--student', '-s', help='åªè¯„åˆ†ç‰¹å®šå­¦ç”Ÿ')

    # æ¸…ç†é€‰é¡¹ï¼ˆç‹¬ç«‹è¿è¡Œï¼Œä¸æ‰§è¡Œè¯„åˆ†ï¼‰
    clean_group = parser.add_mutually_exclusive_group()
    clean_group.add_argument('--clean', choices=['base', 'local', 'all'],
                           help='æ¸…ç†æ–‡ä»¶ï¼šbase=æ¸…ç†base_pathç›®å½•ï¼Œlocal=æ¸…ç†å½“å‰ç›®å½•ï¼Œall=æ¸…ç†ä¸¤ä¸ªç›®å½•')
    clean_group.add_argument('--clean-base', action='store_true', help='ä»…æ¸…ç†base_pathç›®å½•ä¸­çš„è¯„åˆ†ç»“æœæ–‡ä»¶')
    clean_group.add_argument('--clean-local', action='store_true', help='ä»…æ¸…ç†å½“å‰è¿è¡Œç›®å½•ä¸­çš„æ®‹ç•™æ–‡ä»¶')
    clean_group.add_argument('--clean-all', action='store_true', help='æ¸…ç†base_pathå’Œå½“å‰ç›®å½•çš„æ‰€æœ‰æ–‡ä»¶')

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(args.log_level)

    print(f"{Colors.BOLD}{Colors.BLUE}=== è‡ªåŠ¨ Python ä½œä¸šè¯„åˆ†ç³»ç»Ÿ v2.0 ==={Colors.END}")
    print(f"{Colors.CYAN}{'=' * 40}{Colors.END}\n")

    # æ£€æŸ¥æ˜¯å¦ä¸ºæ¸…ç†æ¨¡å¼
    is_clean_mode = args.clean or args.clean_base or args.clean_local or args.clean_all

    if is_clean_mode:
        # æ¸…ç†æ¨¡å¼ï¼šåªæ‰§è¡Œæ¸…ç†æ“ä½œï¼Œä¸è¿›è¡Œè¯„åˆ†
        print(f"ğŸ—‘ï¸  {Colors.BOLD}æ–‡ä»¶æ¸…ç†æ¨¡å¼{Colors.END}")

        try:
            # åŠ è½½é…ç½®ï¼ˆç”¨äºè·å–base_pathï¼‰
            config = load_config(args.config)

            # æ‰§è¡Œç›¸åº”çš„æ¸…ç†æ“ä½œ
            if args.clean == 'base' or args.clean_base:
                print(f"\nğŸ—‘ï¸  æ¸…ç†base_pathç›®å½•...")
                clean_previous_results(args.config)
            elif args.clean == 'local' or args.clean_local:
                print(f"\nğŸ—‘ï¸  æ¸…ç†å½“å‰è¿è¡Œç›®å½•...")
                clean_local_directory()
            elif args.clean == 'all' or args.clean_all:
                print(f"\nğŸ—‘ï¸  æ¸…ç†base_pathç›®å½•...")
                clean_previous_results(args.config)
                print(f"\nğŸ—‘ï¸  æ¸…ç†å½“å‰è¿è¡Œç›®å½•...")
                clean_local_directory()

            print(f"\nâœ… {Colors.GREEN}æ¸…ç†å®Œæˆï¼{Colors.END}")
            return

        except Exception as e:
            print(f"\nâŒ {Colors.RED}æ¸…ç†å¤±è´¥: {e}{Colors.END}")
            return

    try:
        # è¯„åˆ†æ¨¡å¼ï¼šæ­£å¸¸çš„è¯„åˆ†æµç¨‹
        print(f"ğŸ“Š {Colors.BOLD}è¯„åˆ†æ¨¡å¼{Colors.END}")

        # åŠ è½½é…ç½®
        print(f"\nâš™ï¸  {Colors.BOLD}åˆå§‹åŒ–ç³»ç»Ÿ...{Colors.END}")
        config = load_config(args.config)
        print(f"  âœ“ é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")

        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        client = OpenAI(
            api_key=config['api_key'],
            base_url=config['base_url'],
            timeout=config['request_timeout']
        )
        print(f"  âœ“ APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

        # åˆå§‹åŒ–è¯„åˆ†æ ‡å‡†
        criteria = GradingCriteria(args.criteria) if args.criteria else GradingCriteria()
        print(f"  âœ“ è¯„åˆ†æ ‡å‡†åŠ è½½æˆåŠŸ")

        # åˆå§‹åŒ–è¯„åˆ†å™¨
        grader = Grader(client, config['model'], criteria)
        if args.no_cache:
            grader.cache = {}  # æ¸…ç©ºç¼“å­˜

        # åˆå§‹åŒ–è¿›åº¦ç®¡ç†å™¨
        progress_manager = ProgressManager() if args.resume or args.retry_failed else None
        if args.retry_failed and progress_manager:
            progress_manager.reset_failed()
            print(f"  âœ“ å‡†å¤‡é‡è¯•å¤±è´¥çš„ä½œä¸š")

        # è·å–ä½œä¸šåˆ—è¡¨
        base_path = config['base_path']
        submissions = get_submissions(base_path)

        # è¿‡æ»¤ç‰¹å®šå­¦ç”Ÿ
        if args.student:
            submissions = [(sid, path) for sid, path in submissions if sid == args.student]
            if not submissions:
                print(f"{Colors.RED}æœªæ‰¾åˆ°å­¦ç”Ÿ {args.student} çš„ä½œä¸š{Colors.END}")
                return

        print(f"  âœ“ å‘ç° {len(submissions)} ä»½ä½œä¸š\n")

        # åŠ è½½æ¨¡æ¿
        template_content = get_template_content(base_path)

        # å¼€å§‹è¯„åˆ†
        print(f"ğŸš€ {Colors.BOLD}å¼€å§‹è¯„åˆ†...{Colors.END}")
        print(f"  å¹¶å‘æ•°: {args.parallel if args.parallel > 1 else 'é¡ºåºæ‰§è¡Œ'}")

        results = []
        failed_count = 0

        if args.parallel > 1:
            # å¹¶å‘è¯„åˆ†
            with concurrent.futures.ThreadPoolExecutor(max_workers=args.parallel) as executor:
                futures = []
                for student_id, file_path in submissions:
                    future = executor.submit(
                        grade_single_submission,
                        (student_id, file_path, grader, template_content, progress_manager)
                    )
                    futures.append(future)

                # ä½¿ç”¨è¿›åº¦æ¡
                with tqdm(total=len(futures), desc="è¯„åˆ†è¿›åº¦") as pbar:
                    for future in concurrent.futures.as_completed(futures):
                        result = future.result()
                        if result:
                            results.append(result)
                            if not result['success']:
                                failed_count += 1
                        pbar.update(1)
        else:
            # é¡ºåºè¯„åˆ†
            with tqdm(total=len(submissions), desc="è¯„åˆ†è¿›åº¦") as pbar:
                for student_id, file_path in submissions:
                    result = grade_single_submission(
                        (student_id, file_path, grader, template_content, progress_manager)
                    )
                    if result:
                        results.append(result)
                        if not result['success']:
                            failed_count += 1
                    pbar.update(1)

        success_count = len([r for r in results if r['success']])
        print(f"\nâœ“ è¯„åˆ†å®Œæˆ: æˆåŠŸ {success_count} ä»½, å¤±è´¥ {failed_count} ä»½\n")

        # ç›¸ä¼¼åº¦æ£€æµ‹
        similarity_results = []
        if not args.no_similarity and len(submissions) > 1:
            print(f"ğŸ” {Colors.BOLD}æ‰§è¡Œç›¸ä¼¼åº¦æ£€æµ‹...{Colors.END}")
            checker = SimilarityChecker(threshold=config.get('similarity_threshold', 0.85))

            # å‡†å¤‡ä»£ç å†…å®¹
            code_pairs = []
            for student_id, file_path in submissions:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        code_pairs.append((student_id, f.read()))
                except:
                    continue

            # æ£€æµ‹ç›¸ä¼¼åº¦
            similarity_results = checker.find_similar_submissions(code_pairs)
            if similarity_results:
                print(f"  âš ï¸  å‘ç° {len(similarity_results)} å¯¹ç›¸ä¼¼ä½œä¸š")
                for pair in similarity_results[:5]:  # åªæ˜¾ç¤ºå‰5å¯¹
                    print(f"    - {pair['student1']} â†” {pair['student2']}: "
                          f"{pair['similarity']:.1%} ç›¸ä¼¼åº¦")

        # ç»Ÿè®¡åˆ†æ
        print(f"\nğŸ“Š {Colors.BOLD}ç”Ÿæˆç»Ÿè®¡åˆ†æ...{Colors.END}")
        analyzer = StatisticsAnalyzer(args.config)
        statistics = analyzer.analyze_scores(results)

        # æ‰“å°ç®€è¦ç»Ÿè®¡
        if statistics.get('count', 0) > 0:
            print(f"  å¹³å‡åˆ†: {statistics['mean']}")
            print(f"  æœ€é«˜åˆ†: {statistics['max']}")
            print(f"  æœ€ä½åˆ†: {statistics['min']}")
            print(f"  æ ‡å‡†å·®: {statistics['stdev']}")

        # å¯¼å‡ºç»“æœ
        print(f"\nğŸ’¾ {Colors.BOLD}å¯¼å‡ºç»“æœ...{Colors.END}")
        exporter = ExportManager(args.config)

        export_formats = ['csv', 'excel', 'json', 'markdown'] if args.export == 'all' else [args.export]

        for fmt in export_formats:
            if fmt == 'csv':
                exporter.export_to_csv(results)
            elif fmt == 'excel':
                exporter.export_to_excel(results, similarity_results, statistics)
            elif fmt == 'json':
                exporter.export_to_json(results, {'config': config, 'statistics': statistics})
            elif fmt == 'markdown':
                exporter.export_to_markdown(results, statistics)

        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šå’Œå›¾è¡¨
        analyzer.generate_report(results)
        try:
            analyzer.plot_distribution(results)
        except:
            logger.warning("æ— æ³•ç”Ÿæˆåˆ†å¸ƒå›¾ï¼ˆå¯èƒ½ç¼ºå°‘matplotlibï¼‰")

        print(f"\n{Colors.GREEN}{Colors.BOLD}âœ“ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼{Colors.END}")

    except FileNotFoundError as e:
        print(f"\n{Colors.RED}{Colors.BOLD}é”™è¯¯: {e}{Colors.END}")
        logger.critical(f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\n{Colors.RED}{Colors.BOLD}å‘ç”Ÿé”™è¯¯: {e}{Colors.END}")
        logger.critical("å‘ç”ŸæœªçŸ¥é”™è¯¯", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()